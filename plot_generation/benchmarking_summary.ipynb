{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "if \"PROJECT_ROOT\" not in globals():\n",
    "    PROJECT_ROOT = Path.cwd().parent.resolve()\n",
    "\n",
    "os.chdir(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.axes import Axes\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.transforms import ScaledTranslation\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "from typing import Iterable, Tuple, Literal\n",
    "from utils import ModelForAnalysis\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.style.use(\"my.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = PROJECT_ROOT/\"analysis_results\"\n",
    "\n",
    "LARGELY_SAMPLED_EPITOPES = pd.read_csv(\"analysis_results/CDR3 Levenshtein/ovr_nn_200_shot.csv\").epitope.unique()\n",
    "LARGELY_SAMPLED_EPITOPES_10X = pd.read_csv(\"analysis_results/10x/CDR3 Levenshtein/ovr_nn_200_shot.csv\").epitope.unique()\n",
    "\n",
    "NUM_SHOTS_OF_INTEREST = [1,2,5,10,20,50,100,200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (\n",
    "    ModelForAnalysis(\"SCEPTR\", \"ovr_nn\", \"#7048e8\", \"d\", zorder=2),\n",
    "    ModelForAnalysis(\"TCRdist\", \"ovr_nn\", \"#f03e3e\", \"o\", zorder=1.9),\n",
    "    ModelForAnalysis(\"CDR3 Levenshtein\", \"ovr_nn\", \"#f76707\", \"^\"),\n",
    "    ModelForAnalysis(\"TCR-BERT\", \"ovr_nn\", \"#74b816\", \"s\"),\n",
    "    ModelForAnalysis(\"ESM2 (T6 8M)\", \"ovr_nn\", \"#37b24d\", \"p\"),\n",
    "    ModelForAnalysis(\"ProtBert\", \"ovr_nn\", \"#0ca678\", \"x\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_revised_summary_figure(\n",
    "        models: Iterable[ModelForAnalysis],\n",
    "        ks: Iterable[int],\n",
    "        epitopes: Iterable[str],\n",
    "        # legend_in_axes: bool = False,\n",
    "        # ncols: int = 0\n",
    ") -> Figure:\n",
    "    mean_std_collection = []\n",
    "\n",
    "    for k in ks:\n",
    "        model_dfs = [(model.name, model.load_data(k)) for model in models]\n",
    "        summary_df = pd.DataFrame()\n",
    "        summary_df[\"epitope\"] = model_dfs[0][1][\"epitope\"]\n",
    "        summary_df[\"split\"] = model_dfs[0][1][\"split\"]\n",
    "\n",
    "        for model_name, model_df in model_dfs:\n",
    "            summary_df[model_name] = model_df[\"auc\"]\n",
    "        \n",
    "        summary_df = summary_df[summary_df[\"epitope\"].map(lambda ep: ep in epitopes)]\n",
    "\n",
    "        # get average performance across epitopes per model\n",
    "        avg_performance_df = summary_df.groupby(\"epitope\").aggregate({model.name: \"mean\" for model in models})\n",
    "        avg_performances = avg_performance_df.mean()\n",
    "\n",
    "        # get error bars across epitopes per model\n",
    "        model_averages = summary_df.apply(\n",
    "            lambda row: np.mean(row.iloc[2:]),\n",
    "            axis=\"columns\"\n",
    "        )\n",
    "\n",
    "        delta_df = summary_df.copy()\n",
    "        for model in models:\n",
    "            delta_df[model.name] = delta_df[model.name] - model_averages\n",
    "\n",
    "        variance_by_epitope = delta_df.groupby(\"epitope\").apply(\n",
    "            lambda df: Series(data=(df[model.name].var() for model in models), index=(model.name for model in models)),\n",
    "            include_groups=False\n",
    "        )\n",
    "        stds = np.sqrt(variance_by_epitope.sum()) / len(epitopes)\n",
    "\n",
    "        # append to mean_std collection\n",
    "        mean_std_df = pd.DataFrame(data=(avg_performances, stds), index=(\"mean\", \"std\"))\n",
    "        mean_std_collection.append(mean_std_df)\n",
    "    \n",
    "    # plot results\n",
    "    fig, ax = plt.subplots(figsize=(7/2.54,8/2.54))\n",
    "\n",
    "    for model in models:\n",
    "        mean_stds_for_model = pd.DataFrame([df[model.name] for df in mean_std_collection], index=ks)\n",
    "        ax.errorbar(\n",
    "            x=range(len(ks)),\n",
    "            y=mean_stds_for_model[\"mean\"],\n",
    "            yerr=mean_stds_for_model[\"std\"],\n",
    "            fmt=model.style,\n",
    "            markersize=5,\n",
    "            c=model.colour,\n",
    "            label=model.name,\n",
    "            zorder=model.zorder,\n",
    "            capsize=5\n",
    "        )\n",
    "\n",
    "    ax.set_ylabel(\"Mean AUROC\")\n",
    "    ax.set_xlabel(\"Number of Reference TCRs\")\n",
    "    ax.set_xticks(range(len(ks)), ks)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    new_handles = [\n",
    "        plt.Line2D(\n",
    "            [0], [0],\n",
    "            color=handle[0].get_color(),\n",
    "            lw=handle[0].get_linewidth(),\n",
    "            linestyle=handle[0].get_linestyle(),\n",
    "            marker=handle[0].get_marker(),\n",
    "            markersize=handle[0].get_markersize()\n",
    "        )\n",
    "        for handle in handles\n",
    "        ]\n",
    "    fig.legend(handles=new_handles, labels=labels, loc=\"center left\", bbox_to_anchor=(1,0,1,1))\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = generate_revised_summary_figure(models, NUM_SHOTS_OF_INTEREST, LARGELY_SAMPLED_EPITOPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_benchmark_summary_with_errorbars(\n",
    "    models: Iterable[ModelForAnalysis],\n",
    "    ks: Iterable[int],\n",
    "    epitopes: Iterable[str],\n",
    "):\n",
    "    mean_std_collection = []\n",
    "\n",
    "    for k in ks:\n",
    "        model_dfs = [(model.name, model.load_data(k)) for model in models]\n",
    "        summary_df = pd.DataFrame()\n",
    "        summary_df[\"epitope\"] = model_dfs[0][1][\"epitope\"]\n",
    "        summary_df[\"split\"] = model_dfs[0][1][\"split\"]\n",
    "\n",
    "        for model_name, model_df in model_dfs:\n",
    "            summary_df[model_name] = model_df[\"auc\"]\n",
    "        \n",
    "        summary_df = summary_df[summary_df[\"epitope\"].map(lambda ep: ep in epitopes)]\n",
    "\n",
    "        # get average performance across epitopes per model\n",
    "        avg_performance_df = summary_df.groupby(\"epitope\").aggregate({model.name: \"mean\" for model in models})\n",
    "        avg_performances = avg_performance_df.mean()\n",
    "\n",
    "        # get error bars across epitopes per model\n",
    "        model_averages = summary_df.apply(\n",
    "            lambda row: np.mean(row.iloc[2:]),\n",
    "            axis=\"columns\"\n",
    "        )\n",
    "\n",
    "        delta_df = summary_df.copy()\n",
    "        for model in models:\n",
    "            delta_df[model.name] = delta_df[model.name] - model_averages\n",
    "\n",
    "        variance_by_epitope = delta_df.groupby(\"epitope\").apply(\n",
    "            lambda df: Series(data=(df[model.name].var() for model in models), index=(model.name for model in models)),\n",
    "            include_groups=False\n",
    "        )\n",
    "        stds = np.sqrt(variance_by_epitope.sum()) / len(epitopes)\n",
    "\n",
    "        # append to mean_std collection\n",
    "        mean_std_df = pd.DataFrame(data=(avg_performances, stds), index=(\"mean\", \"std\"))\n",
    "        mean_std_collection.append(mean_std_df.T.stack())\n",
    "\n",
    "    return pd.DataFrame(mean_std_collection, index=ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_benchmark_summary_with_errorbars(models, NUM_SHOTS_OF_INTEREST, LARGELY_SAMPLED_EPITOPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
